{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Title: ADVec\n",
    "I want to create a framework to study active DNA (AttaqSeq or DNAseSeq) sequences for regulatory prediction. This will use ideas from pepword, DNA2Vec and Seq2Vec in order to make consistent vector sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import processSeq\n",
    "import warnings\n",
    "import threading\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "class mycorpuse(object):\n",
    "\tdef __iter__(self):\n",
    "\t\tfor line in open(\"\"):\n",
    "\t\t\tyield line.split()\n",
    "class mycorpusp(object):\n",
    "\tdef __iter__(self):\n",
    "\t\tfor line in open(\"./Data/Learning/unlabeled_train_promoter_GM12878\"):\n",
    "\t\t\tyield line.split()\n",
    "\n",
    "# Load training data\n",
    "def getData(type,cell):\n",
    "\tdata = pd.read_table('./Data/Learning/supervised_'+str(cell)+\"_\"+str(type))\n",
    "\treturn data\n",
    "\n",
    "# Load trained Word2Vec model or train a new model\n",
    "def getWord_model(word,num_features,min_count,type,cell):\n",
    "\tword_model1 = \"\"\n",
    "\tmodel_name = str(cell)+\"_enhancer\"\n",
    "\t\n",
    "\tif not os.path.isfile(\"./\" + model_name):\n",
    "\t\tsentence = LineSentence(\"./Data/Learning/unlabeled_train_enhancer_\"+str(cell),max_sentence_length=15000)\n",
    "\t\tprint \"Start Training Word2Vec model...\"\n",
    "\t\t# Set values for various parameters\n",
    "\t\tnum_features = int(num_features)\t  # Word vector dimensionality\n",
    "\t\tmin_word_count = int(min_count)\t  # Minimum word count\n",
    "\t\tnum_workers = 20\t\t # Number of threads to run in parallel\n",
    "\t\tcontext = 20\t\t\t# Context window size\n",
    "\t\tdownsampling = 1e-3\t # Downsample setting for frequent words\n",
    "\n",
    "\t\t# Initialize and train the model\n",
    "\t\tprint \"Training Word2Vec model...\"\n",
    "\t\tword_model1 = Word2Vec(sentence, workers=num_workers,\\\n",
    "\t\t\t\t\t\tsize=num_features, min_count=min_word_count, \\\n",
    "\t\t\t\t\t\twindow =context, sample=downsampling, seed=1)\n",
    "\t\tword_model1.init_sims(replace=False)\n",
    "\t\tword_model1.save(model_name)\n",
    "\t\tprint word_model1.most_similar(\"CATAGT\")\n",
    "\telse:\n",
    "\t\tprint \"Loading Word2Vec model...\"\n",
    "\t\tword_model1 = Word2Vec.load(model_name)\n",
    "\n",
    "\tword_model2 = \"\"\n",
    "\tmodel_name = str(cell)+\"_promoter\"\n",
    "\tif not os.path.isfile(\"./\" + model_name):\n",
    "\t\tsentence = LineSentence(\"./Data/Learning/unlabeled_train_promoter_\"+str(cell),max_sentence_length=15000)\n",
    "\t\t\n",
    "\t\tprint \"Start Training Word2Vec model...\"\n",
    "\t\t# Set values for various parameters\n",
    "\t\tnum_features = int(num_features)\t  # Word vector dimensionality\n",
    "\t\tmin_word_count = int(min_count)\t  # Minimum word count\n",
    "\t\tnum_workers = 20\t\t # Number of threads to run in parallel\n",
    "\t\tcontext = 20\t\t\t# Context window size\n",
    "\t\tdownsampling = 1e-3\t # Downsample setting for frequent words\n",
    "\n",
    "\t\t# Initialize and train the model\n",
    "\t\tprint \"Training Word2Vec model...\"\n",
    "\t\tword_model2 = Word2Vec(sentence, workers=num_workers,\\\n",
    "\t\t\t\t\t\tsize=num_features, min_count=min_word_count, \\\n",
    "\t\t\t\t\t\twindow=context, sample=downsampling, seed=1)\n",
    "\t\tword_model2.init_sims(replace=False)\n",
    "\t\tword_model2.save(model_name)\n",
    "\t\tprint word_model2.most_similar(\"CATAGT\")\n",
    "\telse:\n",
    "\t\tprint \"Loading Word2Vec model...\"\n",
    "\t\tword_model2 = Word2Vec.load(model_name)\n",
    "\n",
    "\treturn word_model1,word_model2\n",
    "\n",
    "# Split sequences into words\n",
    "def getCleanDNA_split(DNAdata,word):\n",
    "\n",
    "\tdnalist = []\n",
    "\tcounter = 0\n",
    "\tfor dna in DNAdata:\n",
    "\t\tif counter % 100 == 0:\n",
    "\t\t\tprint \"DNA %d of %d\\r\" % (counter, len(DNAdata)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tdna = str(dna).upper()\n",
    "\t\tdnalist.append(processSeq.DNA2Sentence(dna,word).split(\" \"))\n",
    "\n",
    "\t\tcounter += 1\n",
    "\tprint\n",
    "\treturn dnalist\n",
    "\n",
    "def makeFeatureVecs(words, model, num_features,word,k,temp):\n",
    "\tfeatureVec = np.zeros((k,num_features), dtype=\"float32\")\n",
    "\tnwords = 0\n",
    "\tindex2word_set = set(model.index2word)\n",
    "\tlength = len(words)\n",
    "\tfor word in words:\n",
    "\t\tif word in index2word_set:\n",
    "\t\t# divide the words into k parts, add up in each part\n",
    "\t\t\tfeatureVec[math.floor((nwords * k) / length)] += (model[word]) * temp[nwords]\n",
    "\t\t\tnwords =nwords + 1\n",
    "\n",
    "\tfeatureVec = featureVec.reshape(k * num_features)\n",
    "\t#featureVec = featureVec/nwords\n",
    "\treturn featureVec\n",
    "\n",
    "def mean2max(vec):\n",
    "\tlength = len(vec)\n",
    "\tmean1 = np.max(vec[0:int(length*0.5)],axis = 0)\n",
    "\tmean2 = np.max(vec[int(length*0.5):int(length)],axis = 0)\n",
    "\tmaxvec = np.mean([mean1,mean2],axis = 0)\n",
    "\treturn maxvec\n",
    "\n",
    "def getAvgFeatureVecs(data,model1,model2, num_features, word,k,type,cell):\n",
    "\tdnaFeatureVecs = np.zeros((len(data),2*k*num_features), dtype=\"float32\")\n",
    "\tif not os.path.isfile(\"./Data/enhancertfidf\"+str(cell)):\n",
    "\t\tprint \"Getting dictionary\"\n",
    "\t\tCorp = mycorpuse()\n",
    "\t\tdictionary = corpora.Dictionary(Corp)\n",
    "\t\tdictionary.save(\"./Data/enhancerdic\"+str(cell))\n",
    "\t\tcorpus = [dictionary.doc2bow(text) for text in Corp]\n",
    "\t\tprint \"Calculating TFIDF\"\n",
    "\t\ttfidf = models.TfidfModel(corpus)\n",
    "\t\ttfidf.save(\"./Data/enhancertfidf\"+str(cell))\n",
    "\telse:\n",
    "\t\ttfidf = models.TfidfModel.load(\"./Data/enhancertfidf\"+str(cell))\n",
    "\t\tdictionary = corpora.Dictionary.load(\"./Data/enhancerdic\"+str(cell))\n",
    "\tdict1 = {k:v for k, v in dictionary.items()}\n",
    "\n",
    "\tDNAdata1 = getCleanDNA_split(data[\"seq1\"],word)\n",
    "\n",
    "\tcounter = 0\n",
    "\tfor dna in DNAdata1:\n",
    "\n",
    "\t\tif counter % 100 == 0:\n",
    "\t\t\tprint \"DNA %d of %d\\r\" % (counter, len(DNAdata1)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\t\t\n",
    "\t\tvec_bow = dictionary.doc2bow(dna)\n",
    "\t\tvec_tfidf = tfidf[vec_bow]\n",
    "\t\t\n",
    "\t\tfor i in xrange(len(vec_tfidf)):\n",
    "\t\t\tdnaFeatureVecs[counter][0:k*num_features] += model1[dict1[vec_tfidf[i][0]]] * vec_tfidf[i][1]\n",
    "\t\t\n",
    "\t\tcounter += 1\n",
    "\t\n",
    "\tprint\n",
    "\tdel DNAdata1\n",
    "\n",
    "\tcounter = 0\n",
    "\tif not os.path.isfile(\"./Data/promotertfidf\"+str(cell)):\n",
    "\t\tprint \"Getting dictionary\"\n",
    "\t\tCorp = mycorpusp()\n",
    "\t\tdictionary = corpora.Dictionary(Corp)\n",
    "\t\tdictionary.save(\"./Data/promoterdic\"+str(cell))\n",
    "\t\tcorpus = [dictionary.doc2bow(text) for text in Corp]\n",
    "\t\tprint \"Calculating TFIDF\"\n",
    "\t\ttfidf = models.TfidfModel(corpus)\n",
    "\t\ttfidf.save(\"./Data/promotertfidf\"+str(cell))\n",
    "\telse:\n",
    "\t\ttfidf = models.TfidfModel.load(\"./Data/promotertfidf\"+str(cell))\n",
    "\t\tdictionary = corpora.Dictionary.load(\"./Data/promoterdic\"+str(cell))\n",
    "\t\n",
    "\tdict2 = {k:v for k, v in dictionary.items()}\n",
    "\n",
    "\tDNAdata2 = []\n",
    "\tcounter = 0\n",
    "\tfor dna in data[\"seq2\"]:\n",
    "\t\tif counter % 100 == 0:\n",
    "\t\t\tprint \"DNA %d of %d\\r\" % (counter, len(data)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tdna = str(dna).upper()\n",
    "\t\tDNAdata2.append(processSeq.DNA2Sentence(dna,word).split(\" \"))\n",
    "\n",
    "\t\tcounter += 1\n",
    "\n",
    "\tcounter = 0\n",
    "\tprint\n",
    "\n",
    "\tfor dna in DNAdata2:\n",
    "\t\tif counter % 100 == 0:\n",
    "\t\t\tprint \"DNA %d of %d\\r\" % (counter, len(DNAdata2)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tvec_bow = dictionary.doc2bow(dna)\n",
    "\t\tvec_tfidf = tfidf[vec_bow]\n",
    "\t\t\n",
    "\t\tfor i in xrange(len(vec_tfidf)):\n",
    "\t\t\tdnaFeatureVecs[counter][k*num_features:2*k*num_features] += model2[dict2[vec_tfidf[i][0]]] * vec_tfidf[i][1]\n",
    "\t\t\n",
    "\t\tcounter += 1\n",
    "\tprint\n",
    "\tnp.save(\"./Datavecs/datavecs_\"+str(cell)+\"_\"+str(type)+\".npy\",dnaFeatureVecs)\n",
    "\treturn dnaFeatureVecs\n",
    "\n",
    "def run(word, num_features,K,type,cell):\n",
    "\twarnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\tglobal word_model,data,k\n",
    "\n",
    "\tword = int(word)\n",
    "\tnum_features = int(num_features)\n",
    "\tk=int(K)\n",
    "\tword_model=\"\"\n",
    "\tmin_count=10\n",
    "\n",
    "\tword_model1,word_model2 = getWord_model(word,num_features,min_count,type,cell)\n",
    "\n",
    "\t# Read data\n",
    "\tdata = getData(type,cell)\n",
    "\n",
    "\tlength = data.shape[0]\n",
    "\tprint length\n",
    "\n",
    "\tprint \"Generating Training and Testing Vector\"\n",
    "\tdataDataVecs = getAvgFeatureVecs(data,word_model1,word_model2,num_features,word,k,type,cell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
